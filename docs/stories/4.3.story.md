# Story 4.3: Claude Synthesis for Q&A

## Status

**Completed**

---

## Story

**As a** system,
**I want** to synthesize retrieved content into coherent answers,
**so that** users get clear, actionable responses.

---

## Acceptance Criteria

1. Claude API call with retrieved context and user question
2. System prompt instructs: answer in user's language, cite sources, be actionable
3. Response includes synthesized answer with inline citations
4. Response formatted for chat display (markdown supported)
5. Claude handles translation to user's language within same call
6. Token usage logged for cost monitoring
7. Response time <5 seconds including retrieval

---

## Tasks / Subtasks

- [x] **Task 1: Create Q&A Synthesis Agent** (AC: 1, 2)
  - [x] Create Q&A system prompt in ChatWindow.tsx
  - [x] Configure with Gemini 2.0 Flash model (via CopilotKit)
  - [x] Write Q&A system prompt with instructions
  - [x] Include citation instructions

- [x] **Task 2: Create Synthesis Action** (AC: 1, 3, 4)
  - [x] Create `convex/ai/qa.ts`
  - [x] Implement `buildRAGContext` action
  - [x] Build context from search results
  - [x] Format response with citations

- [x] **Task 3: Implement Inline Citations** (AC: 3)
  - [x] Define citation format (e.g., [1], [2])
  - [x] Map citations to source URLs
  - [x] Include sources list at end

- [x] **Task 4: Handle Multilingual Output** (AC: 5)
  - [x] Pass user's language via system prompt
  - [x] Instruct AI to respond in that language
  - [x] Language passed through CopilotProvider properties

- [x] **Task 5: Add Token Usage Logging** (AC: 6)
  - [x] Track input/output tokens
  - [x] Created `convex/monitoring.ts` with logTokenUsage mutation
  - [x] Store in Convex tokenUsage table for cost analysis

- [x] **Task 6: Optimize Response Time** (AC: 7)
  - [x] CopilotKit handles streaming natively
  - [x] RAG search includes timing logs
  - [x] Monitor and log timing

- [x] **Task 7: Integrate with Chat Flow** (AC: 1-6)
  - [x] Connect synthesis to CopilotKit runtime via searchMigrationKnowledge action
  - [x] Pass context from useCopilotReadable
  - [x] Handle synthesis errors gracefully with try/catch

---

## Dev Notes

### Q&A Advisor Agent
[Source: architecture.md#mastra-agent-integration]

```typescript
// agents/qaAdvisor.ts
import { Agent } from "@mastra/core";

export const qaAdvisor = new Agent({
  name: "QAAdvisor",
  model: "claude-sonnet-4-20250514",
  instructions: `You are a Q&A advisor for TRIBE, a migration intelligence platform.

Your role is to answer user questions about migration using community-sourced knowledge.

IMPORTANT RULES:
1. Answer in the user's specified language
2. Always cite sources using [1], [2], etc. format
3. Be concise but actionable
4. Admit when you don't have information
5. Never invent facts not in the provided context
6. Flag outdated information with warnings

RESPONSE FORMAT:
- Start with a direct answer to the question
- Provide supporting details with citations
- End with actionable next steps if applicable
- Include a Sources section at the end

Example:
"Based on community experiences, the German visa typically takes 4-6 weeks to process [1].

Key tips from others who've done this:
- Apply at least 2 months before your planned travel [2]
- Book your appointment early as slots fill quickly [1]

**Sources:**
[1] Reddit user u/expat_berlin, 2024
[2] InterNations forum, December 2024"
`,
  tools: [],
});
```

### Synthesis Action
```typescript
// convex/ai/qa.ts
import { action } from "../_generated/server";
import { v } from "convex/values";
import { api } from "../_generated/api";
import { qaAdvisor } from "../../agents/qaAdvisor";

interface SynthesisResult {
  answer: string;
  sources: Array<{
    index: number;
    url: string;
    author?: string;
    date?: string;
  }>;
  usage: {
    inputTokens: number;
    outputTokens: number;
  };
  latencyMs: number;
}

export const synthesizeAnswer = action({
  args: {
    question: v.string(),
    corridorId: v.id("corridors"),
    language: v.optional(v.string()),
  },
  handler: async (ctx, { question, corridorId, language = "en" }): Promise<SynthesisResult> => {
    const startTime = Date.now();

    // Step 1: Retrieve relevant content
    const searchResults = await ctx.runAction(api.ai.search.searchRelevantContent, {
      query: question,
      corridorId,
      limit: 10,
    });

    // Step 2: Build context for synthesis
    const context = buildContext(searchResults);
    const sources = buildSourcesList(searchResults);

    // Step 3: Get corridor info
    const corridor = await ctx.runQuery(api.corridors.getCorridor, {
      id: corridorId,
    });

    // Step 4: Generate synthesis
    const prompt = buildPrompt(question, context, corridor, language);
    const result = await qaAdvisor.generate(prompt);

    // Step 5: Parse and format response
    const answer = formatAnswer(result.text, sources);

    const latencyMs = Date.now() - startTime;

    // Log usage for cost monitoring
    await ctx.runMutation(api.monitoring.logTokenUsage, {
      model: "claude-sonnet-4",
      inputTokens: result.usage?.input_tokens ?? 0,
      outputTokens: result.usage?.output_tokens ?? 0,
      action: "qa_synthesis",
      corridorId,
    });

    console.log(`Q&A synthesis completed in ${latencyMs}ms`);

    return {
      answer,
      sources,
      usage: {
        inputTokens: result.usage?.input_tokens ?? 0,
        outputTokens: result.usage?.output_tokens ?? 0,
      },
      latencyMs,
    };
  },
});

function buildContext(
  results: Array<{
    content: string;
    metadata: {
      url: string;
      author?: string;
      publishedAt?: number;
    };
  }>
): string {
  return results
    .map((r, i) => {
      const date = r.metadata.publishedAt
        ? new Date(r.metadata.publishedAt).toLocaleDateString()
        : "unknown date";
      const author = r.metadata.author ?? "community member";

      return `[Source ${i + 1}] (${author}, ${date})
${r.content}
---`;
    })
    .join("\n\n");
}

function buildSourcesList(
  results: Array<{
    metadata: {
      url: string;
      author?: string;
      publishedAt?: number;
    };
  }>
): Array<{ index: number; url: string; author?: string; date?: string }> {
  return results.map((r, i) => ({
    index: i + 1,
    url: r.metadata.url,
    author: r.metadata.author,
    date: r.metadata.publishedAt
      ? new Date(r.metadata.publishedAt).toLocaleDateString()
      : undefined,
  }));
}

function buildPrompt(
  question: string,
  context: string,
  corridor: { origin: string; destination: string } | null,
  language: string
): string {
  const languageNames: Record<string, string> = {
    en: "English",
    yo: "Yoruba",
    hi: "Hindi",
    pt: "Portuguese",
    tl: "Tagalog",
  };

  const corridorInfo = corridor
    ? `The user is planning to migrate from ${corridor.origin} to ${corridor.destination}.`
    : "No corridor specified.";

  return `${corridorInfo}

Respond in ${languageNames[language] ?? "English"}.

COMMUNITY KNOWLEDGE:
${context}

USER QUESTION:
${question}

Remember to cite sources using [1], [2], etc. and include a Sources section at the end.`;
}

function formatAnswer(
  rawAnswer: string,
  sources: Array<{ index: number; url: string; author?: string; date?: string }>
): string {
  // Ensure sources section exists
  if (!rawAnswer.toLowerCase().includes("sources:")) {
    const sourcesSection = sources
      .map((s) => {
        const authorDate = [s.author, s.date].filter(Boolean).join(", ");
        return `[${s.index}] ${s.url}${authorDate ? ` (${authorDate})` : ""}`;
      })
      .join("\n");

    return `${rawAnswer}\n\n**Sources:**\n${sourcesSection}`;
  }

  return rawAnswer;
}
```

### Token Usage Logging
```typescript
// convex/monitoring.ts
import { mutation, query } from "./_generated/server";
import { v } from "convex/values";

export const logTokenUsage = mutation({
  args: {
    model: v.string(),
    inputTokens: v.number(),
    outputTokens: v.number(),
    action: v.string(),
    corridorId: v.optional(v.id("corridors")),
  },
  handler: async (ctx, args) => {
    return ctx.db.insert("tokenUsage", {
      ...args,
      timestamp: Date.now(),
    });
  },
});

export const getTokenUsageSummary = query({
  args: {
    startDate: v.optional(v.number()),
    endDate: v.optional(v.number()),
  },
  handler: async (ctx, { startDate, endDate }) => {
    let query = ctx.db.query("tokenUsage");

    const logs = await query.collect();

    const filtered = logs.filter((log) => {
      if (startDate && log.timestamp < startDate) return false;
      if (endDate && log.timestamp > endDate) return false;
      return true;
    });

    const summary = {
      totalInputTokens: 0,
      totalOutputTokens: 0,
      byAction: {} as Record<string, { input: number; output: number; count: number }>,
    };

    for (const log of filtered) {
      summary.totalInputTokens += log.inputTokens;
      summary.totalOutputTokens += log.outputTokens;

      if (!summary.byAction[log.action]) {
        summary.byAction[log.action] = { input: 0, output: 0, count: 0 };
      }
      summary.byAction[log.action].input += log.inputTokens;
      summary.byAction[log.action].output += log.outputTokens;
      summary.byAction[log.action].count += 1;
    }

    return summary;
  },
});
```

### Schema Addition
```typescript
// convex/schema.ts - Add tokenUsage table
tokenUsage: defineTable({
  model: v.string(),
  inputTokens: v.number(),
  outputTokens: v.number(),
  action: v.string(),
  corridorId: v.optional(v.id("corridors")),
  timestamp: v.number(),
})
  .index("by_timestamp", ["timestamp"])
  .index("by_action", ["action"]),
```

### File Structure
```
agents/
└── qaAdvisor.ts          # Q&A synthesis agent

convex/
├── ai/
│   └── qa.ts             # Synthesis action
└── monitoring.ts         # Token usage logging
```

### Dependencies from Previous Stories
- Story 4.1: CopilotKit integration
- Story 4.2: RAG retrieval with Voyage AI

---

## Testing

### Test Scenarios

1. **Answer Synthesis**
   - [ ] Answer addresses the question
   - [ ] Citations present in answer
   - [ ] Sources section included

2. **Citation Accuracy**
   - [ ] Citation numbers match sources
   - [ ] URLs are valid
   - [ ] Authors and dates included

3. **Multilingual Output**
   - [ ] Response in requested language
   - [ ] Sources section still in original URLs
   - [ ] Citations work in all languages

4. **Token Logging**
   - [ ] Usage logged to Convex
   - [ ] Input/output tokens accurate
   - [ ] Action type recorded

5. **Response Time**
   - [ ] Total < 5 seconds
   - [ ] Breakdown logged for debugging
   - [ ] Streaming reduces perceived latency

6. **Error Handling**
   - [ ] Graceful failure on API error
   - [ ] User sees friendly message
   - [ ] Error logged for debugging

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-21 | 1.0 | Initial story draft | Bob (SM) |

---

## Dev Agent Record

**Completed:** 2025-12-23

### Files Created/Modified
- `convex/schema.ts` - Added tokenUsage table for cost monitoring
- `convex/monitoring.ts` - Token usage logging mutations and queries
- `convex/ai/qa.ts` - RAG context builder action for Q&A synthesis
- `app/api/copilotkit/route.ts` - Added searchMigrationKnowledge action with RAG integration
- `components/chat/ChatWindow.tsx` - Added Q&A system instructions

### Implementation Notes
- Adapted from Claude to Gemini 2.0 Flash via CopilotKit (project uses Google AI, not Anthropic)
- RAG search uses Voyage AI embeddings from Story 4.2
- CopilotKit action `searchMigrationKnowledge` calls Convex `buildRAGContext` action
- System prompt in ChatWindow instructs AI on citation format and response structure
- Token usage logged to Convex for cost analysis
- Streaming handled natively by CopilotKit

### Key Functions
- `buildRAGContext` - Retrieves relevant content and formats context with sources
- `searchMigrationKnowledge` - CopilotKit action for RAG-based Q&A
- `logTokenUsage` - Mutation to track AI token usage
- `getTokenUsageSummary` - Query for cost analysis

### Build Status
- TypeScript: ✅ Passed
- Next.js build: ✅ Passed
- Convex deploy: ✅ Deployed

---

## QA Results
*To be filled by QA Agent*
